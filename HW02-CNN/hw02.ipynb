{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>HW2 Convolutional neural networks for text classification\n",
    "</center></h1>\n",
    "\n",
    "In this homework you will learn how to build a simple convolutional neural networks (1 convolution layer with max pooling + 1 activation layer) from scratch, and use the model to solve text classification problem. As optional, you also have a chance to build real life CNN models using Keras + Tensorflow and use it to challenge the model you build from scratch. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1. Math preliminaries </h3>\n",
    "\n",
    "Please answer all these questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the form of sigmoid function $σ(z)$ ? Show that $σ′(z) = σ(z)[1 − σ(z)]$.\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "$$\\sigma(z)=\\frac{1}{1+e^{-z}}$$\n",
    "$$\\sigma(z)^\\prime = \\frac{e^{-z}}{(1+e^{-z})^2} = \\frac{1}{1+e^{-z}}(\\frac{e^{-z}}{1+e^{-z}}) = \\sigma(x)(1-\\sigma(z))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Another popular activation function is $tanh(z) = \\frac{e^z-e^{-z}}{e^z+e^{-z}}$ , show that $tanh′(z) = 1 − tanh(z)^2$.\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "$$\\tanh(z)^\\prime = \\frac{(e^z + e^{-z})^2 - (e^z - e^{-z})^2}{(e^z + e^{-z})^2} = 1 - \\frac{(e^z - e^{-z})^2}{(e^z + e^{-z})^2} = 1 - tanh(z)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For a single variable single layer perceptron with sigmoid activation function (equivalent\n",
    "to LR) and loss function defined as:\n",
    "<center>$\\hat{y}_i = σ ( w_1 x_i + w_0 )$ </center>\n",
    "<center>$L(w_0, w_1) = \\sum_i y_i lg(\\hat{y}_i)+(1−y_i)lg(1−\\hat{y}_i)$ </center>\n",
    "Show that:\n",
    "<center>$\\frac{∂L}{∂w_1} =\\sum_i(y_i−\\hat{y}_i)x_i$ </center>\n",
    "<center>$\\frac{∂L}{∂w_0} =\\sum_i(y−\\hat{y}_i)$  </center>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**  \n",
    "Let\\`s add a dummy dimension to $x$ so that we can write the mapping from $x$ to $\\hat{y}$ as $\\hat{y_i} = \\sigma(x^T_iw)$.  \n",
    "$$\\frac{\\partial \\hat{y_i}}{\\partial w} = \\hat{y_i}(1 - \\hat{y_i})x_i = [\\hat{y_i}(1 - \\hat{y_i})x_i, \\quad \\hat{y_i}(1-\\hat{y_i})]^T$$\n",
    "Then  \n",
    "$$\\frac{\\partial L(w)}{\\partial w} = \\frac{\\partial L(w)}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial w} = \\sum_i (\\frac{y_i}{\\hat{y_i}} - \\frac{(1 - y_i)}{(1 - \\hat{y_i})})\\frac{\\partial \\hat{y_i}}{\\partial w} = \\sum_i \\frac{(y_i - \\hat{y_i})}{\\hat{y_i}(1 - \\hat{y_i})} \\frac{\\partial \\hat{y_i}}{\\partial w} = [\\sum_i (y_i - \\hat{y_i})x_i,\\quad \\sum_i (y_i - \\hat{y_i})]^T$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For column vectors $\\vec{x}$ and $\\vec{w}$ , and a symmetric matrix $\\overleftrightarrow{M}$, define the gradient operator:\n",
    "<center> $∇_\\vec{x} = (\\frac{∂}{∂x_0}, \\frac{∂}{∂x_1}, ...,\\frac{∂}{∂x_n})^T$ </center>\n",
    "show that:\n",
    "<center> $∇_x(\\vec{w}^T\\vec{x}) = \\vec{w}$ </center>\n",
    "<center> $∇_x(\\vec{x}^T\\vec{w}) = \\vec{w}$ </center>\n",
    "<center> $∇_x(\\vec{w}^T\\overleftrightarrow{M}\\vec{x}) = \\overleftrightarrow{M}\\vec{w}$ </center>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**  \n",
    "$$∇_x(\\vec{w}^T\\vec{x}) = ∇_x(\\sum_i x_i w_i) = [w_0,...,w_n]^T = \\vec{w}$$  \n",
    "\n",
    "$$∇_x(\\vec{x}^T\\vec{w}) = ∇_x(\\sum_i x_i w_i) = [w_0,...,w_n]^T = \\vec{w}$$\n",
    "\n",
    "$$∇_x(\\vec{w}^T\\overleftrightarrow{M}\\vec{x}) = ∇_x(\\sum_i w^T m_i x_i) = [w^Tm_1,...,w^Tm_n]^T = (w^TM)^T = \\overleftrightarrow{M}\\vec{w}$$\n",
    "where $M = [m0,...m_n]$, i.e. $m_i$ is the columns vector of $M$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Let’s expand Q3 to a more general case. Suppose there is a single layer perceptron with multiple variables:\n",
    "<center> $\\hat{y}_i = σ( \\vec{w}^T \\vec{x_i} )$ </center>\n",
    "<center>$L(\\vec{w}) = \\sum_i y_i lg(\\hat{y}_i)+(1−y_i)lg(1−\\hat{y}_i)$ </center>\n",
    "show that:\n",
    "<center> $∇_\\vec{w}L(\\vec{w}) = \\sum_i(y_i - \\hat{y}_i)\\vec{x_i}$ </center>\n",
    "(hint: use the notation defined in Q4)\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "**Solution:**  \n",
    "Showed in Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. In a CNN illustrated as Fig 1, suppose the loss function is:\n",
    "<center> $L(\\overleftrightarrow{U}, \\vec{w}) = \\sum_i y_i lg(\\hat{y}_i)+(1−y_i)lg(1−\\hat{y}_i)$ </center>\n",
    "From the conclusion in Q5, we can get that:\n",
    "<center> $∇_w L(\\overleftrightarrow{U}, \\vec{w}) = \\sum_i (y_i -\\hat{y}_i)\\vec{h}^{(i)}$ </center>\n",
    "Can you calculate $∇_{u_i} L(U,w)$ using similar techniques?\n",
    "\n",
    "<img src=\"CNN.png\" style=\"width:700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**  \n",
    "*Change $u_i$ to $u_j$ for clearer reference(i: sample index, j: filter index), otherwise quite confusion...*  \n",
    "Define cost function $l$ such that $L(U, w) = \\sum_i l(y_i, \\hat{y_i})$. Then we have\n",
    "$$∇_{u_j} L(\\overleftrightarrow{U}, \\vec{w}) = \\sum_i \\frac{\\partial l}{\\partial h_j} \\frac{\\partial h_j}{\\partial u_j} = \\sum_i (y_i - \\hat{y_i})w_j(1 - h_j^2)x_m$$\n",
    "where $m = \\arg\\max_{p} u_j x_p \\forall p \\in [1, n-k+1]$.  \n",
    "More generally, we have:\n",
    "$$∇_u L(\\overleftrightarrow{U}, \\vec{w}) = \\sum_i (y_i - \\hat{y_i})w \\otimes (\\mathbf{1} - h\\otimes h)\\otimes X$$\n",
    "where $\\otimes$ is elementwise multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2. Coding exercise </h3>\n",
    "\n",
    "Follow the instruction in the notebook, and implement the missing code to build the CNN classifier from scratch. Note that the training might be very slow. Consider reducing the training data size and vocabulary size for testing your code. Ask questions in Piazza/Wechat if you get blocked.\n",
    "\n",
    "Hint: In this CNN, words should be one-hot encoded, but we actually numerically encoded it in the code. This is a sparse trick we did to boost the efficiency, try to understand how it works.\n",
    "\n",
    "Some of the key details you will have a chance to implement:\n",
    "- Forward propagation of a CNN network\n",
    "- Backward propagation of a CNN network\n",
    "- Numerical gradient checking \n",
    "- Use Keras and TensorFlow to implement more complex CNN networks\n",
    "    \n",
    "You are given the following files:\n",
    "- `hw02.ipynb`: Notebook file with starter code\n",
    "- `train.txt`: Training set to train your model\n",
    "- `test.txt`: Test set to report your model’s performance\n",
    "- `sample_prediction.csv`: Sample file your prediction result should look like\n",
    "- `utils/`: folder containing all utility code for the series of homeworks\n",
    "\n",
    "<h3> 3. Deliverables (zip them all) </h3>\n",
    "\n",
    "- pdf version of your final notebook.\n",
    "- Use the best model you trained, generate the prediction for test.txt, name the\n",
    "output file prediction.csv (Be careful: the best model in your training set might not\n",
    "be the best model for the test set).\n",
    "- After you finished the run, does the model perform better than the bag of words\n",
    "model you built last week? What do you think that contributes to the difference in\n",
    "performance?\n",
    "- HW2_writeup.pdf: summarize the method you used and report their performance.\n",
    "If you worked on the optional task, add the discussion. Add a short essay\n",
    "discussing the biggest challenges you encounter during this assignment and\n",
    "what you have learnt.\n",
    "\n",
    "(**You are encouraged to add the writeup doc into your notebook\n",
    "using markdown/html langauge, just like how this notes is prepared**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============== Coding Starts Here ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T22:47:18.404322Z",
     "start_time": "2020-03-01T22:47:18.235083Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# add utils folder to path\n",
    "p = os.path.dirname(os.getcwd())\n",
    "if p not in sys.path:\n",
    "    sys.path = [p] + sys.path\n",
    "\n",
    "from utils.hw2 import load_data, save_prediction, read_vocab\n",
    "from utils.general import sigmoid, tanh, show_keras_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T04:40:29.169465Z",
     "start_time": "2019-03-18T04:40:29.086590Z"
    }
   },
   "source": [
    "# CNN model \n",
    "Complete the code block in the cells in this section.\n",
    "\n",
    "* step1: Implement the pipeline method to process the raw input\n",
    "* step2: Implement the forward method\n",
    "* step3: Implement the backward method\n",
    "* step4: Run the cell below to train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str, lmtzr=None, verbose=False):\n",
    "    \"\"\"Preprocess text data: remove symbols, stop words, and apply tokenization and lemmatization\"\"\"\n",
    "    if verbose:\n",
    "        print('='*80)\n",
    "        print('Preprocess Text Data')\n",
    "    text = text.strip()\n",
    "    \n",
    "    # remove symbols\n",
    "    text = re.sub(\"[^A-Za-z0-9' ]+\", ' ', text.lower().strip())\n",
    "    \n",
    "    # tokenization\n",
    "    if verbose:\n",
    "        print('_'*80)\n",
    "        print('Tokenization')\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        print('downloading tokenizers/punkt.zig from nltk')\n",
    "        nltk.download('punkt')\n",
    "    text = word_tokenize(text)\n",
    "\n",
    "    # remove stopwords\n",
    "    if verbose:\n",
    "        print('_' * 80)\n",
    "        print('Remove stopwords')\n",
    "    try:\n",
    "        nltk.data.find('corpora/stopwords.zip')\n",
    "    except LookupError:\n",
    "        print('downloading corpora/stopwords.zig from nltk')\n",
    "        nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "\n",
    "    # lemmatization\n",
    "    if verbose:\n",
    "        print('_' * 80)\n",
    "        print('Lemmatization')\n",
    "    if not lmtzr:\n",
    "        try:\n",
    "            nltk.data.find('corpora/wordnet.zip')\n",
    "        except LookupError:\n",
    "            print('downloading corpora/wordnet.zig from nltk')\n",
    "            nltk.download('wordnet')\n",
    "        lmtzr = WordNetLemmatizer()\n",
    "    text = [lmtzr.lemmatize(word) for word in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: np.ndarray):\n",
    "    '''sigmoid for np.ndarray'''\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, vstack\n",
    "from scipy.signal import correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(y, yhat):\n",
    "    return (-y*np.log(yhat) - (1-y)*np.log(1-yhat)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T00:54:57.880092Z",
     "start_time": "2020-03-12T00:54:57.598477Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNTextClassificationModel:\n",
    "    def __init__(self, vocab, sentence_length=10, window_size=2, F=100, alpha=0.05, random_state=0):\n",
    "        \"\"\"\n",
    "        F: number of filters\n",
    "        alpha: back propagatoin learning rate\n",
    "        \"\"\"\n",
    "        \n",
    "        assert sentence_length >= window_size, \"Sentence size cannot be shorter than the window size\"\n",
    "        self.vocab = vocab\n",
    "        self.vectorizer = CountVectorizer(binary=True)\n",
    "        self.vectorizer.fit(self.vocab)\n",
    "        self.vocab_size = len(self.vectorizer.vocabulary_)\n",
    "        self.sentence_length = sentence_length\n",
    "        self.window_size = window_size\n",
    "        self.filter_size = len(vocab) * window_size\n",
    "        self.F = F\n",
    "        self.alpha = alpha\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(seed=random_state)\n",
    "        \n",
    "        # U and w are the weights of the hidden layer, see Fig 1 in the pdf file\n",
    "        # U is the weight matrix of the 1D convolutional layer with shape: voc_size * window_size by num_filter\n",
    "        self.U = np.random.normal(loc=0, scale=0.01, size=(F, self.window_size, self.vocab_size))\n",
    "        # w is the weights of the activation layer (after max pooling)\n",
    "        self.w = np.random.normal(loc=0, scale=0.01, size=(F + 1))\n",
    "        \n",
    "    def pipeline(self, X, padding=True):\n",
    "        \"\"\"\n",
    "        Data processing pipeline to:\n",
    "        1. Tokenize, Normalize the raw input\n",
    "        2. Translate raw data input into numerical encoded vectors with one-hot encoding\n",
    "        \n",
    "        :param X: raw data input\n",
    "        :param padding: whether to use padding or chopping the input sentence to the given length; if False, use bag-of-words, i.e. add one-hot encoding of all words together\n",
    "        :return: sparse matrix\n",
    "        \"\"\"\n",
    "        X2 = [preprocess_text(x) for x in X]\n",
    "        \n",
    "        if padding:\n",
    "            X2 = [x[:self.sentence_length] + ['']*(self.sentence_length - len(x)) for x in X2]\n",
    "            # apply one-hot encoding and concatenate all words of a sentence\n",
    "            X2 = [hstack([self.vectorizer.transform([y]) for y in x]) for x in X2]\n",
    "        else:\n",
    "            # bag of words\n",
    "            X2 = [self.vectorizer.transform([' '.join(x)]) for x in X2]\n",
    "\n",
    "        return vstack(X2)\n",
    "          \n",
    "    def train(self, X_train, y_train, X_dev, y_dev, nEpoch=50, batch_size=30, raw_text=True):\n",
    "        \"\"\"\n",
    "        Function to fit the model\n",
    "        :param X_train, X_dev: raw data input\n",
    "        :param y_train, y_dev: label \n",
    "        :nEpoch: number of training epoches\n",
    "        \"\"\"\n",
    "        train_score = []\n",
    "        \n",
    "        if raw_text:\n",
    "            X_train = self.pipeline(X_train).A\n",
    "            X_train.reshape(len(X_train), self.sentence_length, self.vocab_size)\n",
    "            X_dev = self.pipeline(X_dev)\n",
    "            X_dev.reshape(len(X_dev), self.sentence_length, self.vocab_size)\n",
    "        else:\n",
    "            X_train = X_train.A.reshape(X_train.get_shape()[0], self.sentence_length, self.vocab_size)\n",
    "            X_dev = X_dev.A.reshape(X_dev.get_shape()[0], self.sentence_length, self.vocab_size)\n",
    "        \n",
    "        n_batch = len(X_train)//batch_size\n",
    "        kf = KFold(n_batch, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        for epoch in range(nEpoch):\n",
    "            print(f'{\"=\"*40} Epoch: {epoch+1} START {\"=\"*40}\\n')\n",
    "            t1 = time()\n",
    "            for i, idx in enumerate(tqdm(kf.split(X_train))):\n",
    "                \n",
    "                t3 = time()\n",
    "                self.fit(X_train[idx[1], :], y_train[idx[1]])\n",
    "                t4 = time()\n",
    "                if i % 100 == 0:\n",
    "                    print(f'{\"*\"*20} training batch{i}/{n_batch},\\tbatch shape: {X_train[idx[1], :].shape}\\t\\ttraining time: {t4-t3:.3f}seconds {\"*\"*20}')\n",
    "            t2 = time()\n",
    "            \n",
    "            prob_train = self.predict(X_train, return_prob=True)\n",
    "            t5 = time()\n",
    "            prob_dev = self.predict(X_dev, return_prob=True)\n",
    "            t6 = time()\n",
    "            accuracy_train = accuracy_score(y_train, np.where(prob_train>0.5, 1, 0))\n",
    "            accuracy_dev = accuracy_score(y_dev, np.where(prob_dev>0.5, 1, 0))\n",
    "            loss_train = logistic_loss(y_train, prob_train)\n",
    "            loss_dev = logistic_loss(y_dev, prob_dev)\n",
    "            \n",
    "            train_score.append((accuracy_train, accuracy_dev, loss_train, loss_dev))\n",
    "            \n",
    "            print(f'\\tTrain accuracy: {accuracy_train:.6f}\\tDev accuracy: {accuracy_dev:.6f}\\n\\tTrain loss: {loss_train:.6f}\\tDev loss: {loss_dev:.6f}\\n\\ttraining time: {t2-t1: .3f}seconds\\tpredict train set time: {t5-t2: .3f}seconds\\tpredict dev set time: {t6-t5: .3f}seconds\\n{\"=\"*40} Epoch: {epoch+1} END {\"=\"*40}\\n')\n",
    "            \n",
    "        return train_score\n",
    "        \n",
    "    def fit(self, Xd, y):\n",
    "        \"\"\"\n",
    "        :param Xd: encoded words, dense matrix\n",
    "        :param y: target\n",
    "        \"\"\"\n",
    "        \n",
    "        self.backward(Xd, y)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, Xd, return_prob=False):\n",
    "        \"\"\"\n",
    "        :param Xd: encoded words, dense matrix\n",
    "        \"\"\"\n",
    "        \n",
    "        prob = self.forward(Xd)[\"yhat\"]\n",
    "        if return_prob:\n",
    "            return prob\n",
    "        else:\n",
    "            return np.where(prob>0.5, 1, 0)\n",
    "    \n",
    "    def forward(self, Xd):\n",
    "        \"\"\"\n",
    "        :param Xd: encoded words, dense matrix\n",
    "        :return: a result dictionary containing 3 items -\n",
    "        result['yhat']: \\hat y in Fig 1.\n",
    "        result['h']: the hidden layer output after max pooling, h = [h1, ..., hf,1]\n",
    "        result['hid']: argmax of F filters, e.g. j of x_j\n",
    "        e.g. for the ith filter u_i, tanh(word[hid[j], hid[j] + window_size]*u_i) = h_i\n",
    "        \"\"\"\n",
    "        h = []\n",
    "        hid = []\n",
    "#         pdb.set_trace()\n",
    "        # layer 1. compute h and \n",
    "        t1 = time()\n",
    "        for j in range(self.F):\n",
    "            # TODO: apply some trice to speed up...\n",
    "            conv = correlate(Xd, self.U[j][None, :, :], mode='valid')\n",
    "            # apply activation                                                                                                                                                                                                                                                                                                                                        \n",
    "            hid.append(conv.argmax(axis=1))\n",
    "            h.append(np.tanh(conv.max(axis=1)))\n",
    "        t2 = time()\n",
    "#         print(f'{self.F} filters, compute convolution, {t2 - t1:.5f} seconds, {(t2-t1)/self.F:.5f} seconds per filter')\n",
    "        \n",
    "        h = np.hstack(h)\n",
    "        hid = np.hstack(hid)\n",
    "        # layer 2. compute probability\n",
    "        h = np.hstack([h, np.ones((len(h), 1))])  # add bias term\n",
    "        yhat = sigmoid(h.dot(self.w))\n",
    "    \n",
    "        return {\"yhat\": yhat, \"h\": h, \"hid\": hid}\n",
    "    \n",
    "    def backward(self, Xd, y):\n",
    "        \"\"\"\n",
    "        Update the U, w using backward propagation\n",
    "        \n",
    "        :param Xd: encoded words, dense matrix\n",
    "        :param label: int 0 or 1\n",
    "        :return: None\n",
    "        \n",
    "        update weight matrix/vector U and V based on the loss function\n",
    "        \"\"\"\n",
    "        res = self.forward(Xd)\n",
    "        yhat = res[\"yhat\"]\n",
    "        h = res[\"h\"]\n",
    "        hid = res[\"hid\"]\n",
    "\n",
    "        # update U and w here\n",
    "        \"\"\"\n",
    "        Implement your code here\n",
    "        \"\"\"\n",
    "        dw = self._calc_gradient_w(y, res['yhat'], res['h'])\n",
    "        du = self._calc_gradient_U(Xd, y, res['yhat'], res['h'], res['hid'])\n",
    "        self.w += self.alpha * dw\n",
    "        self.U += self.alpha * du\n",
    "\n",
    "    def _calc_gradient_w(self, y, yhat, h):\n",
    "        return (h*(y - yhat)[:, None]).mean(axis=0)\n",
    "    \n",
    "    def _calc_gradient_U(self, Xd, y, yhat, h, hid):\n",
    "#         pdb.set_trace()\n",
    "        t1 = time()\n",
    "        a = (((1 - h**2)*(y*(y - yhat))[:, None])[:, :-1]*self.w[None, :-1]).T[:, :, None, None]\n",
    "        t2 = time()\n",
    "        # too slow....\n",
    "        argmax_indices = self._get_argmax_indices(hid)\n",
    "        b = Xd[np.arange(len(y))[:, None], argmax_indices]\n",
    "        t3 = time()\n",
    "#         print(f'compute gradient U, a: {t2 - t1:.5f} seconds, b: {t3 - t2: .5f} seconds')\n",
    "        du = (a*b).mean(axis=1)\n",
    "        return du\n",
    "    \n",
    "    def _get_argmax_indices(self, hid):\n",
    "        s, f = hid.shape\n",
    "        indices = []\n",
    "        for j in range(f):\n",
    "            by_filter = []\n",
    "            for i in range(s):\n",
    "                by_filter.append(np.r_[np.s_[hid[i, j]:hid[i, j]+self.window_size]])\n",
    "            indices.append(np.array(by_filter))\n",
    "        return np.array(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.text, data.target\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X[:2000], y[:2000], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = CNNTextClassificationModel(vocab, sentence_length=30, window_size=5, F=15, alpha=0.01, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cls.pipeline(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = cls.pipeline(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Epoch: 1 START ========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch0/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.570seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:40,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.386seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:20,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.494seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [02:01,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.374seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [02:40,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch400/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.377seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [03:19,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch500/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.381seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [03:59,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch600/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.380seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [04:38,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch700/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.393seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [05:18,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch800/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.374seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [05:55,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch900/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.367seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [06:32,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1000/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.365seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [07:10,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.403seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [07:47,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.363seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [08:24,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.366seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [09:01,  2.59it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 0.519286\tDev accuracy: 0.486667\n",
      "\tTrain loss: 0.692991\tDev loss: 0.693227\n",
      "\ttraining time:  541.438seconds\tpredict train set time:  864.363seconds\tpredict dev set time:  232.431seconds\n",
      "======================================== Epoch: 1 END ========================================\n",
      "\n",
      "======================================== Epoch: 2 START ========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch0/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.457seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:37,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.366seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:13,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.399seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:50,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.357seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [02:27,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch400/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.373seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [03:06,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch500/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.363seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [03:44,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch600/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.364seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [04:21,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch700/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.364seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [04:58,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch800/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.363seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [05:35,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch900/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.360seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [06:12,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1000/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.360seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [06:50,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.495seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [07:47,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.515seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [08:41,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.502seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [09:33,  2.44it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 0.519286\tDev accuracy: 0.486667\n",
      "\tTrain loss: 0.692936\tDev loss: 0.693239\n",
      "\ttraining time:  573.478seconds\tpredict train set time:  732.580seconds\tpredict dev set time:  224.843seconds\n",
      "======================================== Epoch: 2 END ========================================\n",
      "\n",
      "======================================== Epoch: 3 START ========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch0/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.433seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:35,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.348seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:10,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:45,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.444seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [02:20,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch400/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.347seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [02:55,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch500/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [03:30,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch600/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.359seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [04:05,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch700/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.347seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [04:40,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch800/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [05:16,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch900/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [05:51,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1000/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [06:26,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.347seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [07:01,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [07:37,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [08:12,  2.84it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 0.519286\tDev accuracy: 0.486667\n",
      "\tTrain loss: 0.692870\tDev loss: 0.693236\n",
      "\ttraining time:  492.402seconds\tpredict train set time:  668.579seconds\tpredict dev set time:  222.236seconds\n",
      "======================================== Epoch: 3 END ========================================\n",
      "\n",
      "======================================== Epoch: 4 START ========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch0/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.377seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:35,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:10,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:45,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.341seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [02:20,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch400/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.342seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [02:55,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch500/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [03:30,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch600/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [04:05,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch700/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.341seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [04:40,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch800/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [05:15,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch900/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [05:50,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1000/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.353seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [06:25,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [07:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [07:35,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [08:10,  2.85it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 0.519286\tDev accuracy: 0.486667\n",
      "\tTrain loss: 0.692750\tDev loss: 0.693224\n",
      "\ttraining time:  490.481seconds\tpredict train set time:  669.483seconds\tpredict dev set time:  222.252seconds\n",
      "======================================== Epoch: 4 END ========================================\n",
      "\n",
      "======================================== Epoch: 5 START ========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch0/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.371seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:35,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.364seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:10,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.369seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:45,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [02:20,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch400/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.371seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [02:55,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch500/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [03:30,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch600/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [04:05,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch700/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [04:40,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch800/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.347seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [05:15,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch900/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [05:50,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1000/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [06:25,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.342seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [07:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.347seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [07:35,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.347seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [08:10,  2.85it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 0.534286\tDev accuracy: 0.495000\n",
      "\tTrain loss: 0.692527\tDev loss: 0.693170\n",
      "\ttraining time:  490.769seconds\tpredict train set time:  667.290seconds\tpredict dev set time:  223.659seconds\n",
      "======================================== Epoch: 5 END ========================================\n",
      "\n",
      "======================================== Epoch: 6 START ========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch0/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.373seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:35,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:10,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.341seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:45,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [02:20,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch400/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [02:54,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch500/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [03:29,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch600/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [04:04,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch700/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [04:40,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch800/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.342seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [05:15,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch900/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.360seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [05:50,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1000/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [06:25,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [07:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [07:35,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.353seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [08:10,  2.85it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 0.577857\tDev accuracy: 0.505000\n",
      "\tTrain loss: 0.692115\tDev loss: 0.693041\n",
      "\ttraining time:  490.772seconds\tpredict train set time:  667.538seconds\tpredict dev set time:  221.365seconds\n",
      "======================================== Epoch: 6 END ========================================\n",
      "\n",
      "======================================== Epoch: 7 START ========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch0/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.371seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:35,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.340seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:09,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:44,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [02:19,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch400/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.474seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [02:54,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch500/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.342seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [03:29,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch600/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.348seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [04:04,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch700/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.342seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [04:39,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch800/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [05:14,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch900/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.342seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [05:50,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1000/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.362seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [06:26,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [07:01,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [07:36,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.347seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [08:10,  2.85it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 0.560000\tDev accuracy: 0.506667\n",
      "\tTrain loss: 0.691483\tDev loss: 0.692854\n",
      "\ttraining time:  490.861seconds\tpredict train set time:  668.038seconds\tpredict dev set time:  222.221seconds\n",
      "======================================== Epoch: 7 END ========================================\n",
      "\n",
      "======================================== Epoch: 8 START ========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch0/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.374seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:35,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:10,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:45,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [02:20,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch400/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [02:55,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch500/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [03:30,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch600/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [04:05,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch700/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [04:40,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch800/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [05:15,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch900/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [05:51,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1000/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.352seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [06:26,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.348seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [07:01,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.351seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [07:36,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [08:11,  2.85it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 0.505000\tDev accuracy: 0.503333\n",
      "\tTrain loss: 0.690828\tDev loss: 0.692739\n",
      "\ttraining time:  491.952seconds\tpredict train set time:  673.914seconds\tpredict dev set time:  222.257seconds\n",
      "======================================== Epoch: 8 END ========================================\n",
      "\n",
      "======================================== Epoch: 9 START ========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch0/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.374seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:35,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:10,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:44,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [02:19,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch400/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [02:55,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch500/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.342seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [03:30,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch600/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.352seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [04:04,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch700/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [04:40,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch800/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [05:15,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch900/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [05:50,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1000/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.387seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [06:25,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [07:01,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [07:36,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [08:10,  2.85it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 0.497857\tDev accuracy: 0.500000\n",
      "\tTrain loss: 0.690376\tDev loss: 0.692802\n",
      "\ttraining time:  490.774seconds\tpredict train set time:  668.622seconds\tpredict dev set time:  223.312seconds\n",
      "======================================== Epoch: 9 END ========================================\n",
      "\n",
      "======================================== Epoch: 10 START ========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch0/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.370seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:35,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:10,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:45,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.343seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [02:19,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch400/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [02:54,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch500/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.342seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [03:30,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch600/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.338seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [04:04,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch700/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.340seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [04:39,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch800/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [05:14,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch900/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.352seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [05:49,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1000/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.346seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [06:24,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1100/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.345seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [07:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1200/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.344seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [07:35,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** training batch1300/1400,\tbatch shape: (1, 30, 9766)\t\ttraining time: 0.359seconds ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [08:09,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 0.498571\tDev accuracy: 0.501667\n",
      "\tTrain loss: 0.690234\tDev loss: 0.693037\n",
      "\ttraining time:  489.924seconds\tpredict train set time:  679.313seconds\tpredict dev set time:  221.253seconds\n",
      "======================================== Epoch: 10 END ========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 1: SGD\n",
    "train_score = cls.train(X_train, y_train, X_dev, y_dev, nEpoch=10, raw_text=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = pd.DataFrame(train_score, columns=['train_acc', 'val_acc', 'train_loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "_ = train_score.iloc[:, :2].plot(ax=ax)\n",
    "ax2 = ax.twinx()\n",
    "_ = train_score.iloc[:, 2:].plot(ax=ax2, style='.-')\n",
    "_ = ax.set_ylabel('accuracy')\n",
    "_ = ax2.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CNNTextClassificationModel at 0x7f976aa9e1d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data(\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cls.pipeline(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cls.predict(X_test.A.reshape(X_test.get_shape()[0], cls.sentence_length, cls.vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.where(pred, 'pos', 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(pred).to_csv('prediction.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell shows you how the model will be used, you have to finish the cell below before you\n",
    "can run this cell. \n",
    "\n",
    "Once the implementation is done, you should hype tune the parameters to find the best config\n",
    "\n",
    "Note I only selected 2000 data points to speed up debugging, you should use all the data to train the \n",
    "final model\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_data(\"train.txt\")\n",
    "vocab = read_vocab(\"vocab.txt\")\n",
    "# X, y = data.text, data.target\n",
    "# X_train, X_dev, y_train, y_dev = train_test_split(X[:2000], y[:2000], test_size=0.3)\n",
    "# cls = CNNTextClassificationModel(vocab)\n",
    "# cls.train(X_train, y_train, X_dev, y_dev, nEpoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Build your model using Keras + Tensorflow\n",
    "\n",
    "So far we have always forced you to implement things from scratch. You may feel it's overwhelming, but fortunately, it is not how the real world works. In the real world, there are existing tools you can leverage, so you can focus on the most innovative part of your work. We asked you to do all the previous execises for learning purpose, and since you have already reached so far, it's time to unleash yourself and allow you the access to the real world toolings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:06:30.995290Z",
     "start_time": "2019-03-20T05:06:30.927192Z"
    }
   },
   "outputs": [],
   "source": [
    "# First let's see how you can build a similar CNN model you just had using Keras\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:03:13.785839Z",
     "start_time": "2019-03-20T05:03:13.732270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Yes! it is a good practice to do data processing outside the ML model\n",
    "wnet = WordNetLemmatizer()\n",
    "# Numerical encode all the words\n",
    "unknown = vocab['__unknown__']\n",
    "X_train2 = [[vocab.get(wnet.lemmatize(w), unknown) for w in word_tokenize(sent)] for sent in X_train]\n",
    "X_dev2 = [[vocab.get(wnet.lemmatize(w), unknown)for w in word_tokenize(sent)] for sent in X_dev]\n",
    "\n",
    "# Tensorflow does not handle variable length input well, let's unify all input to the same length\n",
    "def trim_X(X, max_length=100, default=vocab['.']):\n",
    "    for i in range(len(X)):\n",
    "        if len(X[i]) > max_length:\n",
    "            X[i] = X[i][:max_length]\n",
    "        elif len(X[i]) < max_length:\n",
    "            X[i] = X[i] + [default] * (max_length - len(X[i]))\n",
    "            \n",
    "    return np.array(X)\n",
    "            \n",
    "X_train2 = trim_X(X_train2, MAX_LENGTH)\n",
    "X_dev2 = trim_X(X_dev2, MAX_LENGTH)\n",
    "\n",
    "\n",
    "# Now we have all the input data nicely encoded with numerical label, and each of the input data are trimmed \n",
    "# to have the same length. We would have needed to further apply one-hot encode for each word. However, this \n",
    "# would be very expensive, since each word will be expanded into a len(vocab) (~10000) length vector. Keras does\n",
    "# not support sparse matrix input at this moment. But don't worry, we will use an advanced technique called embedding\n",
    "# layer. This concept will be introduced in the next lesson. At this moment, you don't have to understand why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:38:00.091414Z",
     "start_time": "2019-03-20T05:37:59.875258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Embedding-1 (Embedding)      (None, 100, 1024)         10241024  \n",
      "_________________________________________________________________\n",
      "Conv1D-1 (Conv1D)            (None, 99, 100)           204900    \n",
      "_________________________________________________________________\n",
      "MaxPooling1D-1 (GlobalMaxPoo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Dense-1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,446,025\n",
      "Trainable params: 10,446,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'RSAHZLURUY.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b017e5608208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mshow_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/qishi/qishi_nlp/NLP-HW-2021/utils/general.py\u001b[0m in \u001b[0;36mshow_keras_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RSAHZLURUY.png'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, GlobalMaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(vocab), input_length=MAX_LENGTH, output_dim=1024, name=\"Embedding-1\"))\n",
    "model.add(Conv1D(filters=100, kernel_size=2, activation=\"tanh\", name=\"Conv1D-1\"))\n",
    "model.add(GlobalMaxPooling1D(name=\"MaxPooling1D-1\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\", name=\"Dense-1\"))\n",
    "print(model.summary())\n",
    "\n",
    "show_keras_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:39:27.542489Z",
     "start_time": "2019-03-20T05:38:02.612896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 22s 194ms/step - loss: 0.6886 - accuracy: 0.5272 - val_loss: 0.6699 - val_accuracy: 0.5933\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 8s 187ms/step - loss: 0.5443 - accuracy: 0.8525 - val_loss: 0.6353 - val_accuracy: 0.6500\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3631 - accuracy: 0.9665 - val_loss: 0.6251 - val_accuracy: 0.6700\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 8s 186ms/step - loss: 0.1678 - accuracy: 0.9916 - val_loss: 0.6669 - val_accuracy: 0.6517\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 8s 192ms/step - loss: 0.0664 - accuracy: 0.9969 - val_loss: 0.7174 - val_accuracy: 0.6617\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.0244 - accuracy: 0.9993 - val_loss: 0.7839 - val_accuracy: 0.6500\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.8418 - val_accuracy: 0.6467\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8868 - val_accuracy: 0.6467\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9281 - val_accuracy: 0.6433\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 8s 186ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9649 - val_accuracy: 0.6400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fafc80f7790>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train2, y_train, epochs=10, validation_data=(X_dev2, y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have shown you have to use an industry level tool to build a CNN model. Hopefully you think it is simpler than the version we built from scratch. Not really? Read Keras Documentation and learn more: https://keras.io/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T07:24:16.164784Z",
     "start_time": "2019-03-19T07:24:16.104613Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Now it's your turn to build some more complicated CNN models\n",
    "\n",
    "\"\"\"\n",
    "Implement your code here\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
